/*
 * Copyright (c) 2009-2012 NVIDIA Corporation.  All rights reserved.
 *
 * NVIDIA Corporation and its licensors retain all intellectual property
 * and proprietary rights in and to this software, related documentation
 * and any modifications thereto.  Any use, reproduction, disclosure or
 * distribution of this software and related documentation without an express
 * license agreement from NVIDIA Corporation is strictly prohibited.
 */

#define ASSEMBLY_SOURCE_FILE 1
#include "nvbl_assembly.h"

        TEXT
        P2ALIGN(2)
        PRESERVE8

/*******
 *  NvU32 NvAbootPrivVaToPa(void* va)
 *******/
        EXPORT  NvAbootPrivVaToPa
NvAbootPrivVaToPa LABEL
        mov     r1, #0x1000
        sub     r1, r1, #1              // 0x00000FFF
        bic     r2, r0, r1              // VA & 0xFFFFF000
        mcr     p15, 0, r2, c7, c8, 0   // V2PPRPC
        mrc     p15, 0, r2, c7, c4, 0   // PAR
        tst     r2, #1                  // translation fault?
        movne   r0, #0                  // Yes, return NULL
        bxne    lr
        bic     r2, r2, r1              // PA & 0xFFFFF000
        and     r0, r0, r1              // VA & 0x00000FFF
        orr     r0, r0, r2              // (PA & 0xFFFFF000) | (VA & 0x00000FFF)
        bx      lr

/*******
 *  NvU32 NvAbootPrivDoJump(NvU32 *, NvU32, NvUPtr)
 *******/
        IMPORT  disableScu
        IMPORT  nvaosCpuCacheSetWayOps
        EXPORT  NvAbootPrivDoJump
NvAbootPrivDoJump LABEL

        // Load up to 4 registers from pKernelRegs into registers 0..n
        mov     r7, r0   // preserve pKernelRegs
        mov     r8, r1   // preserve NumKernelRegs
        mov     r9, r2   // preserve KernelStartAddr
        cmp     r8, #0
        ldrgt   r0, [r7]
        cmp     r8, #1
        ldrgt   r1, [r7, #4]
        cmp     r8, #2
        ldrgt   r2, [r7, #8]
        cmp     r8, #3
        ldrgt   r3, [r7, #12]

        // Disable the MMU, L1 data caches, and AFE. Defer disabling of the
        // instruction cache and branch predictor until just before the
        // hand-off to the OS in order to benefit from the increased
        // performance they provide.
        mov     r6, #0
        mcr     p15, 0, r6, c7, c10, 4      // DSB
        mrc     p15, 0, r4, c1, c0, 0       // SCTLR
        bic     r4, r4, #(1<<0) | (1<<2)    // SCTLR.M: MMU
                                            // SCTLR.C: Data cache
        bic     r4, r4, #(1<<23)            // SCTLR.AFE: Access Flag Enable
        mcr     p15, 0, r4, c1, c0, 0       // SCTLR

        // Disable SMP mode, cache/TLB broadcast, and L1/L2 prefetch.
        mrc     p15, 0, r4, c1, c0, 1       // ACTLR
        bic     r4, r4, #(1<<6)             // SMP
        bic     r4, r4, #7                  // ACTLR.FW | ACTLR.L1 | ACTLR.L2
        mcr     p15, 0, r4, c1, c0, 1       // ACTLR
        mcr     p15, 0, r6, c7, c10, 4      // DSB

        // Disable the SCU, VFP, and invalidate the data cache.
        stmfd   sp!, {r0-r3}
        bl      disableScu
        bl      AbootPrivDisableVfp
        mvn     r0, #0                      // ~0 = invalidate caches
        bl      nvaosCpuCacheSetWayOps
        ldmfd   sp!, {r0-r3}

        // Disable L1 instruction cache and branch predictor.
        mrc     p15, 0, r4, c1, c0, 0       // SCTLR
        bic     r4, r4, #(1<<11) | (1<<12)  // SCTLR.Z: Branch predictor
                                            // SCTLR.I: Instruction cache
        mcr     p15, 0, r4, c1, c0, 0       // SCTLR

        // Invalidate the instruction and TLBs.
        mcr     p15, 0, r6, c7, c5, 0       // instruction cache invalidate
        mcr     p15, 0, r6, c7, c5, 4       // ISB
        mcr     p15, 0, r6, c8, c7, 0       // invalidate TLBs
        mcr     p15, 0, r6, c7, c10, 4      // DSB

        // Switch to supervisor mode with interrupts disabled
        msr     cpsr_fsxc, #0xd3
        mov     r4, r9

        EXPORT  NvAbootToKernelHandoff
NvAbootToKernelHandoff LABEL    // Export handoff point for JTAG debugger support

        // Jump to the kernel's start address
        bx      r4
        b       .


#ifdef CONFIG_TRUSTED_FOUNDATIONS
/*
 * NvAbootPrepareBoot_TF
 *        r0-r3 kernel params
 *        r8 : num kernel regs
 *        r9 : tfsw params
 */
NvAbootPrepareBoot_TF LABEL
        stmfd   sp!, {r0-r5, r8-r10}

        // Copy Trusted Foundations binary/keys to secure memory
        mov     r0, r9
        bl      NvAbootCopyTFImageAndKeys
        ldmfd   sp!, {r0-r5, r8-r10}

        // set r0 to ColdBoot
        mov     r0, #1

        // set r1 to TF_BOOT_PARAMS
        adr     r1, TFSW_Params_BootParams
        ldr     r1, [r1]

        // jump to secureos start address
        adr     r9, TFSW_Params_StartAddr
        ldr     r9, [r9]
        bx      r9
        b       .

/*
 * Holds pointers to the BootParams and the SecureOS entry
 * point, filled in during NvAbootTFPrepareBootParams.
 */
        EXPORT TFSW_Params_BootParams
TFSW_Params_BootParams LABEL
        .word 0x0
        EXPORT TFSW_Params_StartAddr
TFSW_Params_StartAddr LABEL
        .word 0x0

/*******
 * void NvAbootPrivDoJump_TF( NvU32 *pKernelRegs,
                            NvU32 NumKernelRegs, TFSW_PARAMS *pTfswParams);
 * r0 : pKernelRegs
 * r1 : NumKernelRegs
 * r2 : pTfswParams
 *******/
        IMPORT disableScu
        IMPORT  nvaosCpuCacheSetWayOps
        EXPORT NvAbootPrivDoJump_TF
NvAbootPrivDoJump_TF LABEL

        //  Load up to 4 registers from pKernelRegs into registers 0..n
        mov r7, r0   // preserve pKernelRegs
        mov r8, r1   // preserve NumKernelRegs
        mov r9, r2   // preserve pTfswParams
        cmp r8, #0
        ldrgt r0, [r7]
        cmp r8, #1
        ldrgt r1, [r7, #4]
        cmp r8, #2
        ldrgt r2, [r7, #8]
        cmp r8, #3
        ldrgt r3, [r7, #12]

        // Disable the MMU, L1 data caches, and AFE. Defer disabling of the
        // instruction cache and branch predictor until just before the
        // hand-off to the OS in order to benefit from the increased
        // performance they provide.
        mov     r6, #0
        mcr     p15, 0, r6, c7, c10, 4      // DSB
        mrc     p15, 0, r4, c1, c0, 0       // SCTLR
        bic     r4, r4, #(1<<0) | (1<<2)    // SCTLR.M: MMU
                                            // SCTLR.C: Data cache
        bic     r4, r4, #(1<<23)            // SCTLR.AFE: Access Flag Enable
        mcr     p15, 0, r4, c1, c0, 0       // SCTLR

        // Disable SMP mode, cache/TLB broadcast, and L1/L2 prefetch.
        mrc     p15, 0, r4, c1, c0, 1       // ACTLR
        bic     r4, r4, #(1<<6)             // SMP
        bic     r4, r4, #7                  // ACTLR.FW | ACTLR.L1 | ACTLR.L2
        mcr     p15, 0, r4, c1, c0, 1       // ACTLR
        mcr     p15, 0, r6, c7, c10, 4      // DSB

        // Disable the SCU, VFP, and invalidate the data cache.
        stmfd   sp!, {r0-r3,r9}
        bl      disableScu
        bl      AbootPrivDisableVfp
        mvn     r0, #0                      // ~0 = invalidate caches
        bl      nvaosCpuCacheSetWayOps
        ldmfd   sp!, {r0-r3,r9}

        // Disable L1 instruction cache and branch predictor.
        mrc     p15, 0, r4, c1, c0, 0       // SCTLR
        bic     r4, r4, #(1<<11) | (1<<12)  // SCTLR.Z: Branch predictor
                                            // SCTLR.I: Instruction cache
        mcr     p15, 0, r4, c1, c0, 0       // SCTLR

        // Invalidate the instruction and TLBs.
        mcr     p15, 0, r6, c7, c5, 0       // instruction cache invalidate
        mcr     p15, 0, r6, c7, c5, 4       // ISB
        mcr     p15, 0, r6, c8, c7, 0       // invalidate TLBs
        mcr     p15, 0, r6, c7, c10, 4      // DSB

        // Switch to supervisor mode with interrupts disabled
        msr     cpsr_fsxc, #0xd3

        EXPORT  NvAbootToKernelHandoff_TF
NvAbootToKernelHandoff_TF LABEL    // Export handoff point for JTAG debugger support

        // jump to the kernel's start address
        /*
         r0-r3 kernel params
         r8 : num kernel regs
         r9 : tfsw params
         */
        adr     r4, NvAbootPrepareBoot_TF
        b       NvAbootToKernelHandoff
#endif


/*******
 *  void NvAbootPrivDisableVfp(void) (not exported)
 *******/
#if defined(__GNUC__)
#define FPSCR cr1
#define FPEXC cr8
#define FMXR(_reg_, _vreg_) mcr p10, 7, _reg_, _vreg_, cr0, 0
#else
/*  RVDS 2.2 doesn't like the cp15-based syntax. */
#define FPSCR fpscr
#define FPEXC fpexc
#define FMXR(_reg_, _vreg_) fmxr _vreg_, _reg_
#endif

AbootPrivDisableVfp LABEL
#if !NO_FPU
        mov     r0, #0
        FMXR(r0, FPSCR)
        mov     r0, #0
        FMXR(r0, FPEXC)
#endif
        bx      lr

/*******
 *  void NvAbootPrivSanitizeUniverse(NvAbootHandle)
 *******/
        IMPORT  AbootPrivGicDisableInterrupts
        IMPORT  nvaosPl310InvalidateDisable
        IMPORT  NvOsDataCacheWritebackInvalidate
        EXPORT  NvAbootPrivSanitizeUniverse
NvAbootPrivSanitizeUniverse LABEL
        stmfd   sp!, {lr}

        //  put the CPU into atomic mode -- interrupts disabled
        msr     cpsr_fsxc, #0xdf

        // Disable the interrupt controller
        bl      AbootPrivGicDisableInterrupts

        // Flush and invalidate the L1 data cache.
        bl      NvOsDataCacheWritebackInvalidate

        // Disable the data cache to keep it from being re-dirtied with
        // subsequent data accesses.
        mrc     p15, 0, r4, c1, c0, 0       // SCTLR
        bic     r4, r4, #(1<<2)             // SCTLR.C
        mcr     p15, 0, r4, c1, c0, 0       // SCTLR

        // Invalidate and disable the L2 data cache
        bl      nvaosPl310InvalidateDisable
        ldmfd   sp!, {pc}

    END
